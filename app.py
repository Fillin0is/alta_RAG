import streamlit as st
from llm_connector import LLMConnector, EmbedConnector
from vector_store_pg import VectorStore
from retriever import AnswerSearch
from config import DB_PARAMS, params_config


def initialize_system():
    with st.spinner("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤..."):
        db = VectorStore(params_config.embedders.embedding_3_small, DB_PARAMS)
        llm = LLMConnector()
        embedder = EmbedConnector()
        retriever = AnswerSearch(db.conn, embedder)
    return llm, retriever


def chat_interface(llm, retriever):
    st.title("ü§ñ –ê–ª—å—Ç–∞-—á–∞—Ç")

    if "messages" not in st.session_state:
        st.session_state.messages = []

    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    if prompt := st.chat_input("–í–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            try:
                docs = retriever.hybrid_search(prompt)
                context = "\n\n".join([
                    f"[{d['metadata'].get('source', '–ù–µ–∏–∑–≤.')}] {d['page_content']}" for d in docs
                ])
                message_placeholder = st.empty()
                full_response = ""

                response = llm.generate_response(prompt, context)

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—Ç—Ä–∏–º–∏—Ç—Å—è –ª–∏ –æ—Ç–≤–µ—Ç
                if hasattr(response, "__iter__") and not isinstance(response, str):
                    for chunk in response:
                        full_response += chunk or ""
                        message_placeholder.markdown(full_response + "‚ñå")
                    message_placeholder.markdown(full_response)
                else:
                    # –µ—Å–ª–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±—ã—á–Ω—É—é —Å—Ç—Ä–æ–∫—É
                    message_placeholder.markdown(response)

                message_placeholder.markdown(full_response)
                st.session_state.messages.append({"role": "assistant", "content": full_response})
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞: {e}")


def main():
    st.set_page_config(page_title="RAG API", layout="wide")
    llm, retriever = initialize_system()
    chat_interface(llm, retriever)


if __name__ == "__main__":
    main()